# L1-and-L2-Regularization-Lasso-Ridge-Regression
L1 and L2 regularization are two common techniques used in linear regression models to prevent overfitting and improve the generalization performance of the model. They are often used in the context of Lasso and Ridge regression, respectively.

Lasso Regression (L1 Regularization):

Lasso regression adds the sum of the absolute values of the coefficients as a penalty term to the loss function during training. The objective of Lasso regression is to minimize the following cost function:
Cost function = Sum of squared errors + λ * (sum of absolute values of coefficients)

Ridge Regression (L2 Regularization):

Ridge regression, on the other hand, adds the sum of squared values of the coefficients as a penalty term to the loss function during training. The objective of Ridge regression is to minimize the following cost function:
Cost function = Sum of squared errors + λ * (sum of squared values of coefficients)

